{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 5: Resampling Methods - Applied Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize,\n",
    "                         poly,\n",
    "                         sklearn_sm)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import partial\n",
    "from sklearn.model_selection import (train_test_split,\n",
    "                                     cross_validate,\n",
    "                                     KFold,\n",
    "                                     ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Chapter 4, we used logistic regression to predict the probability of default using income and balance on the `Default` data set. We will now estimate the test error of this logistic regression model using the validation set approach. Do not forget to set a random seed before beginning your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a logistic regression model that uses `income` and `balance` to predict `default`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Default = load_data('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Default_train, Default_valid = train_test_split(Default, test_size=5000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.072956\n",
      "         Iterations 10\n"
     ]
    }
   ],
   "source": [
    "# Fit a linear regression using the training set\n",
    "default_mm = MS(['income', 'balance'])\n",
    "X_train = default_mm.fit_transform(Default_train)\n",
    "y_train = Default_train['default'] == 'Yes'\n",
    "model = sm.Logit(y_train, X_train)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029000000000000026"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform predictions on validation set\n",
    "X_valid = default_mm.transform(Default_valid)\n",
    "y_valid = Default_valid['default'] == 'Yes'\n",
    "valid_pred = results.predict(X_valid)\n",
    "\n",
    "# Overall fraction of misclassified observations\n",
    "1 - np.mean(y_valid == (valid_pred > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9394    0.000014\n",
       "898     0.000247\n",
       "2398    0.008043\n",
       "5906    0.002046\n",
       "2343    0.000298\n",
       "          ...   \n",
       "3996    0.001859\n",
       "5889    0.000034\n",
       "4577    0.008793\n",
       "8600    0.000735\n",
       "847     0.000131\n",
       "Length: 5000, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the process three times, using three diferent splits of the observations into a training set and a validation set. Comment on the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector to store the confusion matrices for the splits\n",
    "C = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078193\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078611\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.073792\n",
      "         Iterations 10\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    Default_train, Default_valid = train_test_split(Default, test_size=5000)\n",
    "    X_train = default_mm.fit_transform(Default_train)\n",
    "    y_train = Default_train['default'] == 'Yes'\n",
    "    model = sm.Logit(y_train, X_train)\n",
    "    results = model.fit()\n",
    "\n",
    "    X_valid = default_mm.transform(Default_valid)\n",
    "    y_valid = Default_valid['default'] == 'Yes'\n",
    "    valid_pred = results.predict(X_valid)\n",
    "\n",
    "    C.append(confusion_matrix(valid_pred > 0.5, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr, fpr, ppv, npv, acc = ([] for i in range(5))\n",
    "\n",
    "for c in C:\n",
    "    tn = c[0,0] \n",
    "    fp = c[0,1]\n",
    "    fn = c[1,0]\n",
    "    tp = c[1,1]\n",
    "    tpr.append((tp / (tp + fn + 0.)))\n",
    "    fpr.append((fp / (fp + tn + 0.)))\n",
    "    ppv.append((tp / (tp + fp + 0.)))\n",
    "    npv.append((1- f n / (fn + tn + 0.)))\n",
    "    acc.append(((tp + tn + 0.) / (tn + fp + fn + tp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR: \n",
      "0.7432 0.8060 0.6471, Average: 0.7321\n",
      "FPR: \n",
      "0.0229 0.0259 0.0248, Average: 0.0246\n",
      "PPV: \n",
      "0.3274 0.2967 0.3107, Average: 0.3116\n",
      "NPV: \n",
      "0.9961 0.9973 0.9938, Average: 0.9957\n",
      "ACC: \n",
      "0.9736 0.9718 0.9696, Average: 0.9717\n"
     ]
    }
   ],
   "source": [
    "def line(l):\n",
    "    return \" \".join( '{:06.4f}'.format(a) for a in l) + ', Average: ' +'{:06.4f}'.format(sum(l)/ len(l))\n",
    "\n",
    "print('TPR: ')\n",
    "print(line(tpr))\n",
    "print('FPR: ')\n",
    "print(line(fpr))\n",
    "print('PPV: ')\n",
    "print(line(ppv))\n",
    "print('NPV: ')\n",
    "print(line(npv))\n",
    "print('ACC: ')\n",
    "print(line(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider a logistic regression model that predicts the probability of `default` using `income`, `balance`, and a dummy variable for `student`. Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for student leads to a reduction in the test error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Default_train, Default_valid = train_test_split(Default, test_size=5000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Default_train['student_yes'] = (Default_train['student'] == 'Yes').astype('int')\n",
    "Default_valid['student_yes'] = (Default_valid['student'] == 'Yes').astype('int')\n",
    "Default_train['default_yes'] = (Default_train['default'] == 'Yes').astype('int')\n",
    "Default_valid['default_yes'] = (Default_valid['default'] == 'Yes').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.072293\n",
      "         Iterations 10\n"
     ]
    }
   ],
   "source": [
    "# Fit a linear regression using the training set\n",
    "default_mm = MS(['income', 'balance', 'student_yes'])\n",
    "X_train = default_mm.fit_transform(Default_train)\n",
    "y_train = Default_train['default_yes']\n",
    "model = sm.Logit(y_train, X_train)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029200000000000004"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform predictions on validation set\n",
    "X_valid = default_mm.transform(Default_valid)\n",
    "y_valid = Default_valid['default_yes']\n",
    "valid_pred = results.predict(X_valid)\n",
    "\n",
    "# Overall fraction of misclassified observations\n",
    "1 - np.mean(y_valid == (valid_pred > 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that adding the dummy student variable doesn't help with validation error rate, in fact, it makes it slightly worse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydata-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
